{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zb8-EUU_nmj",
        "outputId": "88c32432-8b2f-47e5-d351-80052c88154b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
            "  Using cached langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Using cached langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
            "Installing collected packages: langchain-core\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.0.4\n",
            "    Uninstalling langchain-core-1.0.4:\n",
            "      Successfully uninstalled langchain-core-1.0.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 1.0.2 requires langchain-core<2.0.0,>=1.0.2, but you have langchain-core 0.3.79 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.3.79\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Collecting langchain-core<2.0.0,>=1.0.2 (from langchain-openai)\n",
            "  Using cached langchain_core-1.0.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Using cached langchain_core-1.0.4-py3-none-any.whl (471 kB)\n",
            "Installing collected packages: langchain-core\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.4\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.4)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.4 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-text-splitters-1.0.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install  langchain\n",
        "!pip install  langchain-openai\n",
        "!pip install  langchain-community\n",
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjBse9DUAeNR",
        "outputId": "8b7dad83-c222-43d2-ac08-7d3d83af4609"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS, Pinecone, Weaviate, ElasticVectorSearch\n"
      ],
      "metadata": {
        "id": "jOmmvq-5AkJL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the API KEY to actually have access to openAI API"
      ],
      "metadata": {
        "id": "TP3Qi04IERnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "MrkGMvAEBpNo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"PUT THE PAID API KEY HERE\""
      ],
      "metadata": {
        "id": "WgnENPp9Ebya"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.environ.get(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_S9RxsdEmrR",
        "outputId": "113b6bc0-6795-444b-913e-b4e95bd1a654"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting to drive To acces the pdf(s) to read\n"
      ],
      "metadata": {
        "id": "rWpo93fvEqw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir=\"/content/gdrive/My Drive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwEwl9fCEtcB",
        "outputId": "c5848453-6b7f-460b-8e5c-cafc28cb23f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reader= PdfReader('/content/gdrive/My Drive/langchain-PDFS/22_3.pdf')"
      ],
      "metadata": {
        "id": "g0jRRwlFE5MN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5v_iXsaF1x1",
        "outputId": "c46c5c64-7eaa-426f-965f-6f65d3a21734"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PyPDF2._reader.PdfReader at 0x7eb581960ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraction of text from the pdf file"
      ],
      "metadata": {
        "id": "M-heEmWfF97I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text=\"\""
      ],
      "metadata": {
        "id": "j7hOyOzIF7pk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, page in enumerate(reader.pages):\n",
        "  text = page.extract_text()\n",
        "  if text:\n",
        "    raw_text+=text"
      ],
      "metadata": {
        "id": "GLs3S40zGFi9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "p1uJNoULGSK9",
        "outputId": "7f002f5a-00b0-4d13-b7f7-ec700e5f11b4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'18  The Importance of Data Warehouses in the Developmen t… \\n  The Importance of Data Warehouses  \\nin the Development of Computerized Decision Support  Solutions.  \\nA Comparison between Data Warehouses and Data Marts  \\n \\nAlexandru Adrian ȚOLE \\nRomanian – American University, Bucharest, Romania \\nalexandru.tole@gmail.com\\n \\n \\nIn the last decade, the amount of data that an orga nization processes and stores has grown \\nexponentially. In most cases, the data stored is us ed to support the business process through \\naccurate and up-to-date information about the busin ess environment and activity of the \\ncompany. In order for a company\\'s managers to be ca pable of generating the reports they \\nneed to make decisions, one needs a computer system  able to store complex and very large \\nquantities of data. At the same time, for the devel opment of such an information system, one \\nmust take into account the cost of it.  \\nKeywords: Data Warehouse, Data Mart, Top-down, Bottom-up, dat abase, architecture, \\nmanagement system  \\n \\nIntroduction \\nData Warehouses (DW) by means of \\nits data organization and usage \\nelements, are meant to provide helpful \\ntools to assist managers in the decision-\\nmaking process. Many companies deem \\nthe implementation of DW tools as most \\nuseful because the instruments that these \\nsystems offer help with the maintenance \\nand development of the economic unit. \\nCompanies invest large sums in the \\ndevelopment and implementation of such \\nsolutions as they provide essential \\nelements that companies can use to retain \\ncustomers and, at the same time, increase \\ntheir number.  \\nData Warehouses were originally \\nintended for use in areas such as banking, \\ntelecommunications and retailing. \\nHowever, later, they became hugely \\npopular in other areas as well. According \\nto the literature, it is the banking field and \\nthe telecommunications domain that uses \\nthese solutions most frequently, \\nallocating the largest amounts for the \\ndevelopment of data warehouses. \\nInmon estimates the costs for the \\ndevelopment of a solution of the Data \\nWarehouse type as being between \\n500,000 $ and $ 1,000,000 per terabyte \\n[1] and this includes only the \\ninfrastructure. From this perspective, the companies that do not have such financial \\nresources may resort to the implementation \\nof Data Marts (DM), whose costs are much \\nlower. \\nAs far as the definition is concerned, the \\ndata warehouse term can be presented as \"a \\ndatabase that is maintained separately from \\nthe operational databases of the \\norganization\" [2]. By this, we mean that the \\ninformation is extracted from operational \\ndatabases, goes through an ETL type \\nprocess, following to be loaded into the Data \\nWarehouse. These data warehouses are used \\nto support the decision-making process by \\nstoring information in the decision-making \\nprocess. \\nAs the main features of data bases, we \\ndistinguish the following [3]:  \\n• Integration; \\n• Data persistence; \\n• Historical character; \\n• Guidance on topics. \\nThe \"integration\" characteristic of data \\nwarehouses refers to the fact that the source \\nof the information stored is not singular. The \\ndata existing in a DW originate from sources \\nsuch as relational databases, files (e.g. excel, \\nword, xml), etc. This information, before \\nbeing loaded into the DW, goes through \\n1\\n Database Systems Journal  vol. VI, no. 4/2015  19 \\n  processing to be used later in the analysis \\nperformed using other Informatics \\nsolutions.   \\nAnother feature of Data Warehouses is \\nthat they focus on topics that are specific \\nfor the activity of the company, removing \\ninformation that is not relevant for the \\ndecision-making process. Traditional \\nsystems focused more on the particular \\ndata requested by certain departments \\n(compartments) of the economic unit. \\nOver time, these systems have been \\ndeveloped to support the implementation \\nof processes from the beginning to the \\nend. \\nThe historical character of Data \\nWarehouses is that they store information \\nfor an undetermined period of time. This \\nhelps in the achievement of the decision-\\nmaking process because the decision-\\nmakers can make statistical calculations \\nfor certain key indicators. \\nThe information stored in a data \\nwarehouse is permanent and cannot be \\nchanged. Therefore, any changes made in \\nthe DW data sources will have new data \\nas a result, without modifying or deleting \\nthe existing data. It follows that a data \\nwarehouse is stored separately from the \\ndata processed by other applications. \\nNormally, the operations in a data \\nwarehouse are the loading of data and the \\naccess to this information.  \\nAnother feature of a DW is that related to \\nthe origin of the data. It can have \\nsimultaneously, internal and external \\ninformation sources (Fig. 2 - Sources of \\ninformation) to help the decision-making \\nprocess. At the same time, DW includes \\ntools with which users can quickly access \\ndata. \\n \\n(Files, Databases) \\nFig. 1 Sources of information \\nThe notion of \"data warehousing\" is very \\noften used in the making of a data \\nwarehouse. The development of a data \\nwarehouse involves processes such as data \\nintegration, cleansing and consolidating \\nthem. In order to use a data warehouse one \\nneeds most often various applications that \\nhelp with the interpretation of this \\ninformation. These applications allow the \\ndecision-making structures to use \\ninformation in a convenient and easy way \\nfor the decisions-making process. As far as \\nthe \"data warehousing\" term is concerned, \\nthis is interpreted as the process of the \\nmaking of the data warehouse. For the use \\nof the DW it is the Warehouse Database \\nManagement System  [3] term that is used.. \\nThe process of data warehousing is useful \\nbecause it helps the integration of \\nheterogeneous data sources. It is well-known \\nthat large companies collect various types of \\ninformation and load them into databases for \\nlater use in the development of statistics \\nand/or calculation of trends. The integration \\nof information, as well as an as easy as \\npossible access to them constitute a priority \\nfor companies.  \\nWith regard to traditional databases, the \\nintegration of heterogeneous databases is \\ncarried out by means of two elements: \\nwrappers and integrators. As for example, \\nwhen performing a site query, it is a \\ndictionary of metadata that is used to \\ntransform this search into a query \\nappropriate for the sites involved. The result \\nreceived from various sources is integrated \\nin the global response of the query \\nperformed. \\nThe concept of data query will result in a \\ncomplex process of integration and filtering \\nthat is reflected on the processing resources. \\nThus, it is ineffective and can become \\nexpensive, in terms of hardware \\narchitecture, to achieve frequent queries, \\nespecially if they require aggregations. Data \\nwarehousing provides an alternative to the \\ntraditional concept regarding the integration \\nof databases via the \"update-driven\" [4] 20  The Importance of Data Warehouses in the Developmen t… \\n  characteristic, through which the data \\nfrom sources are queried and stored in the \\ndata warehouse to be analyzed later. For \\nexample, in contrast to the databases that \\nstore information on accessing the email \\nby Yahoo users, a data warehouse does \\nnot present information updated in real \\ntime.  \\nAlthough a data warehouse has the \\ndisadvantage of supplying recent data, it \\nprovides a high performance by \\nintegrating databases whereas data is \\ncopied, processed, summarized and \\nrestructured into a semantic data \\ncollection [5]. At the same time, the \\nprocess of data warehouse query does not \\ninterfere with processes from local \\nsources. A data warehouse is also \\nadvantageous due to the fact that it stores \\nand integrates historical data and \\nprovides facilities regarding advanced \\nquery features.  \\n  Data warehouse provides access to the \\nintegrated data of the company, which \\nhad been previously blocked or restricted. \\nUsers can establish a secure connection to \\nthe data warehouse via a PC. Security is \\nprovided on the one hand by means of the \\nuser interface (UI) and on the other hand \\nthrough the database server. \\nThe data warehouse has the quality of \\nproviding a single version of the truth. \\nThe information available in the DW \\nhave a high quality due to the \\ntransformation process they have gone \\nthrough. This is so if a single data source \\nis used, thus putting an end to the debate \\non the veracity of the data. The data \\nwarehouse comes to be a unique source \\nof information for the top-management. It \\nshould be noted that the existence of a \\nsingle variant of truth is dependent upon \\nfirm agreement on the terms used. For \\nexample, the term \"possible client\" can \\nhave multiple meanings, such as former \\nclients, customers whose contracts are \\nabout to expire, the entities addressed \\noffering deals etc. Surely these issues \\ninfluence the decision-making process.   The fact that a data warehouse integrates \\nhistorical data determines the relevance of \\ndecisions taken by managers because, in \\ngeneral, decisions are based on previous \\nexperiences as well. For example, \\ncomparing monthly reports leads to the \\nmaking of decisions regarding investments. \\nData warehouses can be used to accurately \\nrecord the past, making the OLTP systems \\navailable to focus on the correct registration \\nof current transactions. Historical data are \\nloaded and integrated with other existing \\ndata in the DW to provide rapid access. \\nThe types of dynamic reports as well as the \\nOLAP query tools allow users to visualize \\nthe data from DW from different \\nperspectives and at different levels of detail. \\nThese possibilities offered by Data \\nWarehouses reduce time and effort \\nconcerning the collection, processing and \\nfiltering of information coming from various \\nsources.  \\nThe operational processes are vastly \\ndifferent as compared to the decision-\\nmaking processes. The attempt to integrate \\nthe decision-making information with the \\noperational information makes system \\nmaintenance became a major problem. Thus, \\nstarting from the operational processes, the \\nData Warehouse provides a separate \\narchitecture in relation to the \\nimplementation of decisions. \\n \\n2 Databases architecture \\nA data warehouse consists of a very large \\ndatabase, which contains data that can be \\nused by end-users. In a Data Warehouse \\nthere are several types of information that \\ncorrespond to the users \\' needs, such as the \\nfollowing: \\n\\x01 Detailed data; \\n\\x01 Aggregate data; \\n\\x01 Metadata. \\nMetadata is information embedded in the \\ndata warehouse containing data relating to \\nthe content stored. Metadata includes \\ninformation showing the structure of the \\nexisting data in the data warehouse, their \\norigin, transformation rules, aggregation and \\ncalculation. They have a very important role Database Systems Journal  vol. VI, no. 4/2015  21 \\n  in powering the data warehouse, being \\nused in all the processes of loading of \\ndata and are updated throughout the life \\nof the data warehouse.  \\nThe existence of aggregate data in the \\ndata warehouse increases data \\nredundancy, but it is required, however, \\nto reduce response times regarding Data \\nWarehouse queries. A logical flowchart \\nregarding the basic architecture of a data \\nwarehouse can be seen below (Fig. 3 – \\nBasic architecture of a DW). \\n \\n \\n \\n(Operational databases, Text files, Other \\nsources – Data Warehouse – Metadata, \\nAggregated data, Detailed data – Analysis, \\nReporting) \\nFig. 2 Basic architecture of a DW \\n \\nData warehouses are generally intended \\nfor use by analysts or persons engaged in \\ndecision-making processes concerning \\nthe development of the economic entity. \\nTo achieve this, they need powerful tools \\nthat facilitate access to and use of the \\ninformation stored in data warehouses. \\nThese tools are mostly provided by the \\ndata warehouse. At the same time, a DW \\nsolution can also integrate tools which \\nmeet the need of users for rapid access to \\ninformation or quickly generate reports. \\nThere are specialized tools that can \\ntransform the information in the data \\nwarehouse so as to be presented in the \\nform of graphics and/or diagrames. Here \\none can fiind specialized OLAP \\ninstruments and data mining. \\nThe OLAP-type instruments focus more \\non a multidimensional representation of \\ninformation and allow for rapid analysis \\nof data by means of processes such as \\ndrill down, slice, etc. Thus, the user can obtain results rapidly and can work at \\ndifferent levels of synthesis. \\nData mining -type tools are helping \\ntransform information into knowledge, thus \\nthe term Data Mining is often confused with \\nthe Knowledge Discovery in Databases term \\n[6]. \\n \\n3 Architecture of data warehouses on \\nthree levels \\nFrom the architecture described above we \\ncan build a software solution that is capable \\nof meeting the requirements of all users of \\nthe data warehouse. Figure 4 shows a data \\nwarehouse architecture on three levels: \\nBottom Tier, Middle Tier și Top Tier[7]. \\n \\n \\nFig. 3 Architecture of data warehouses on three \\nlevels \\n(Analysis, Reports, Exit, OLAP Server, Data \\nWarehouse, Internal data, External Data) \\na) Bottom tier:  \\nIncludes the server of the data warehouse \\nand of the data marts. Typically, the \\ndatabases used for building the data \\nwarehouse are relational databases. The data \\nwarehouse is loaded with internal \\ninformation (from the company, from \\nvarious departments) and external (third \\nparty applications used by employees, \\ninformation collected online, files etc.). The \\ninformation is loaded into the data 22  The Importance of Data Warehouses in the Developmen t… \\n  warehouse after they were extracted and \\nprocessed. At the same time, from the \\ndatabase one obtains the information to \\nbe loaded on the data marts to be made \\navailable to users. \\nb) Middle tier: \\nIt is made up of OLAP servers. It uses \\neither a relational model (ROLAP) or a \\nmultidimensional one (MOLAP).  \\nc) Top tier: \\nIt is the level at which the user interacts \\nwith the computer system. At this level \\nyou can generate reports, you can create a \\ndata analysis by means of the tools or you \\ncan achieve the data mining. \\n \\nRalph Kimball and William Inmon had \\ndifferent opinions with regard to the \\ndesign and architecture of data \\nwarehouses. Inmon supported a \"Data \\nMart\" structure, dependent on data, a \\nmethod which is called \"top-down\". This \\nmethod describes an approach by means \\nof which the data warehouse is done first, \\nfollowed by the creation of Data Marts, \\nas satellites that contain data. Kimball has \\napproached the problem differently, in \\nthe sense that he started from the \\ndevelopment of Data Marts to the \\nrealization of the data warehouse. This \\napproach is called \"bottom-up”. \\n \\n4 Top-Down Method  \\nInmon has noticed that it takes the \\ntransfer of data from various OLTP \\nsystems and centralizing them for further \\nanalysis. He considers that the data must \\nbe organized in structures that are \\n\"embedded, non-volatile, subject-oriented \\nand variable in time \"[8]. At the same \\ntime, he thinks that the data must be \\naccessed in a detailed enough level to \\nallow the use of data mining tools. The \\nData Marts, in this case, are seen as being \\ndata sub-sets of the Data Warehouse. \\nData Marts are developed for in each \\ndepartment, so as to later meet the \\nanalysis requirements of the department \\nfor which the data warehouse has been \\ndeveloped  . The top-down method (Fig. 5-Top-Down), \\nin an OLAP environment, starts with  data \\nextraction from the operational data sources. \\nAfterwards, they are loaded into the waiting \\narea, where they are validated and \\nconsolidated in order to ensure a high level \\nof data quality. They are then transferred to \\nthe Operational Data Store (ODS). This \\nstage (ODS) is often omitted in cases where \\nthere occurs a doubling of operational \\ndatabases. At the same time, detailed data \\nare constantly extracted from the operational \\ndata warehouse and hosted temporarily in \\nthe transfer area, following extraction and \\nupload (ETL) in the data warehouse.  \\n  \\n \\nFig. 4 Top-Down \\n \\nThe need for an Operational Data \\nWarehouse is given by the needs of the \\nbusiness process. Whenever the situation \\ncalls for the existence of detailed data in the \\ndata warehouse, then the implementation of \\nan ODS is justified.  \\nOnce the data warehouse processes \\nconcerning the aggregation and \\ncentralization come to an end, the cycle of \\nData Marts updateis resumed by means of \\ndata extraction and upload into the transfer \\nzone in order to subject them to \\ntransformations. This helps to structure data. \\nUpon successful completion of these \\nprocesses, Data Marts can be loaded with \\ndata with a view to be available to users who \\nwork in an OLAP environment. \\n \\n5 Bottom-Up Method \\nRalph Kimball designed data warehouses \\nusing Data Marts connected to it by means \\nof a \"bus\" [9] type architecture (Fig. 6-Bus \\nArchitecture). This architecture \\nencompassed all the common elements of a \\nData Mart. Kimball considered that  by Database Systems Journal  vol. VI, no. 4/2015  23 \\n  using these elements, users can \\ninterrogate all the Data Marts at the same \\ntime. This renders the data store more \\nvirtual than physical. Thus, all Data \\nMarts can be found on a single server or \\nmay be located on different servers, \\nspread across the organization, forming a \\nvirtual data warehouse.  \\nApplying the Kimball model, we can \\nconsider as a Data Mart the cubes as well, \\nbuilt by using OLAP. This model \\nprovides flexibility by means of the rapid \\nrealization of Data Marts. \\n \\n \\n \\nFig. 6 Bus Architecture \\n \\nBy means of this model, Data Marts can \\nbe carried out more quickly and the \\nstructuring of common data, according to \\nthis architecture, eliminates the effort \\nmade whenever the need to achieve more \\nData Marts occurs.  \\nBottom-up approach reverses the \\nhierarchical relationships between Data \\nWarehouse (DW) and Data Mart (DM). \\nDM are loaded directly, through the area \\nof transfer, with the data obtained from \\ndifferent sources. In this case, the \\nexistence of ODS is optional, being \\nsubject to the company\\'s needs. However, \\nthis approach increases the complexity of \\nthe process of transformation of the data. \\nThe standard procedure by which the DM are updated from the Operational Data \\nWarehouse, not directly from relational \\ndatabases, provides data consolidation, \\nbeing the recommended approach for use of \\nthe resulting data.  \\nData stream in the Bottom-Up method \\nbegins by the extraction of data from \\noperational databases, their upload them in \\nthe transfer area where they are processed \\nand then consolidated and loaded into the \\nOperational Data Warehouse. The \\ninformation on the ODS is replaced or \\nsupplemented by the newly-loaded data. \\nUpon completion of these operations, the \\ndata from the ODS are again loaded in the \\ntransfer area and processed to fit the \\nstructure of the data available in Data Marts. \\nThe data uploaded into the DM are \\ntransferred into the waiting area to be \\nsubjected to processes of aggregation, \\nsummary, etc. to be able to be loaded into \\nthe DW and made available to the end user \\nto be analyzed. \\nTherefore, the bottom-up approach starts \\nfrom the company\\'s need to process certain \\ninformation and highlights Data Marts as \\nbeing the primary source of information for \\nmaking an analysis[10]. \\n \\n6 Data Mart \\nInmon defines the Data Mart as \"a subset of \\nthe data warehouse that has been converted \\nto meet the needs of a department\" [11]. \\nTherefore, a relevant data mart contains \\ninformation from a particular area/section. \\nThis information will either be used only by \\nthe members of the department, or it will \\nhelp to make the reports at the level of \\nmanagement to assist in the decision-making \\nprocess.  \\nIt is very important that when you develop a \\ncomputer system having the role of a data \\nwarehouse, it must be sufficiently flexible so \\nas to be able to adapt to changes that may \\ntake place. The flexibility of the solution is \\nalso given by its capacity to connect to all \\nlevels of the company and retrieve the \\nnecessary data. If new servers are added to \\ncompensate for the need of capacity or \\ncomputing power, processes concerning the 24  The Importance of Data Warehouses in the Developmen t… \\n  system configuration, optimization, and \\nadministration may become difficult if \\nthe operations are repeated whenever a \\nhardware architecture component is \\nreplaced or added. To overcome this \\nproblem you can opt for the development \\nof data subsets called Data Marts (Fig. 7-\\nData Mart). A data mart is a data \\nwarehouse that contains information \\nspecific to an organization department or \\nactivity, as opposed to a data warehouse \\nthat can meet the needs of the entire \\ncompany. In this context, the resources \\nrequired to develop a data mart are much \\nfewer than those needed for a data \\nwarehouse. \\n \\n \\n(Human Resources, User, Accounting, User) \\nFig. 7 Data Mart \\n Consequently, you can use existing \\ninformation in common, connecting the data \\nmarts for each department, in order to \\nachieve an infrastructure based on which \\none can develop solutions to assist the \\ndecision-making process. \\nDue to the very low cost of data mart \\ndevelopment, most companies opt out for \\ndeveloping them. At the same time, the costs \\nrelating to the administration are also low \\nand the flexibility offered by them is large \\nenough to help the transition to Data \\nWarehouse if needed. \\n \\n7 Data Warehouse vs. Data Mart \\nChoosing a solution of the type of Data \\nWarehouse or Data Mart depends, to a large \\nextent, on the needs of the company. If the \\ncompany aims at processing and aggregating \\nthe data in order to achieve a solid system to \\nassist in the decision-making process, then it \\nis recommended that you implement a Data \\nWarehouse solution. At the same time, a \\nData Warehouse includes historical data, \\nwhich helps the development of statistics. If \\nthe economic entity only needs data storage  \\nfor each department or if all the departments \\nuse the same computerized solution to enter \\nspecific data, then a Data Mart will be \\ncapable enough to meet such needs. \\n \\nTable 1 Data Warehouse and Data Mart Characteristics \\nData Warehouse \\nData Mart \\n\\x01 Comprises both internal \\n(the company departments) \\nand external data (internet, \\nother files); \\n\\x01 Stores detailed data; \\n\\x01 Contains historical data \\nistorice (that can span the \\nentire Data Warehouse life-\\nduration); \\n\\x01 It does not necessarily use a \\ndimensional model; \\n\\x01 Contains metadata; \\n\\x01 High implementation costs. \\n\\x01 Comprises data specific to a \\ndepartment or area of interest; \\n\\x01 Uses a dimensional model \\n(the„Star” model, most of the \\ntime); \\n\\x01 Contains informations that can \\nbe transmitted to the data \\nwarehouse (if it exists); \\n\\x01 Low implementation costs and \\nduration. \\n \\nAs can be seen in the table above, a Data \\nWarehouse contains more types of \\ninformation than a Data Mart. Moreover, in order to achieve a decision support \\nsolution, a DW is more useful because it \\ncontains data that have undergone Database Systems Journal  vol. VI, no. 4/2015  25 \\n  processing before being loaded. Thus, the \\nquality of information increases, the \\ngenerated reports showing the actual data.  \\nA Data Mart is superior to a Data \\nWarehouse in terms of implementation \\nand maintenance costs. At the same time, \\na Data Mart can compete fairly easily \\nwith a DW with regard to the information \\nsupport provided for the achievement of \\ndecision-making solutions because small \\nand medium-sized firms often use a \\nsingle software to enter and record the \\nbusiness process information. Usually, \\nsmall and medium-sized businesses use a \\nsoftware which comprises several \\nmodules specific to departments. In this \\nsense, the implementation of an extra \\nmodule (if the computer solution allows \\nit) with a view to generate reports and \\ngraphs is quite easy and the costs are \\nconsiderably lower than the development \\nof a solution which operates on the basis \\nof a Data Warehouse. \\n \\n8 Conclusions and Proposals \\nWith regard to the development of a \\ncompany, the choice of appropriate \\ncomputer solutions represents a very \\nimportant element. Computer solutions \\nrefer to both the hardware infrastructure \\n(servers, network, firewall, etc.) and the \\nsystems software (operating systems, \\ndatabases, specialized software) that will \\nhelp the business process. In this context, \\nthere are several elements that must be \\ntaken into account in the development of \\na computer solution:  \\n\\x01 Company needs; \\n\\x01 Financial resources of the company \\nregarding the development of a \\ncomputer-based solution; \\n\\x01 Complexity and prevalence of \\ninformation. \\nWhen a company wishes to implement a \\nsolution that works with information \\navailable both within the company and \\nexternally, and leading to the \\nimplementation of software systems to \\nsupport the decision-making process, \\nthen a Data Warehouse solution is appropriate. The advantage it offers is given \\nby the quality of the stored data (going \\nthrough a process of ETL), includes \\nhistorical data (data recorded during the \\nwhole DW lifespan), provides long-term \\nstability. \\nIf the economic entity does not work with \\ncomplex information and/or the information \\nsource is compact (only one department or \\nmultiple departments working with one soft) \\nthen you can deploy a Data Mart. By means \\nof the data existing in such a Data Mart \\nthere can be built,  as well as in the case of a \\nDW, a software solution to support \\nmanagers in the decision-making process. At \\nthe same time, the costs of implementing a \\nData Mart solution are lower as compared to \\nthose of a Data Warehouse solution.  \\nThe advantages that a Data Mart has got as \\ncompared to a DW are: low implementation \\ncosts and reduced duration of deployment. \\nAt the same time, on the basis of the Data \\nMarts existing in a company a Data \\nWarehouse can be develop at all times.  \\n \\nReferences \\n[1] William H. INMON, „ Some Straight \\nTalk About The Costs Of Data \\nWarehousing ”, http://goo.gl/cYGGH6\\n; \\n[2] Abordări de tip Data Warehousing - \\nImplementare în Microsoft SQL Server \\n2005 - http://goo.gl/NPl9x1\\n; \\n[3] David J. DEWITT, Samuel MADDEN, \\nMichael STONEBRAKER, „ How to \\nBuild a High-Performance Data \\nWarehouse ”, http://goo.gl/PT60BZ\\n; \\n[4] Morgan KAUFMANN, „ Data \\nwarehousing ”, https://goo.gl/bY1E8k\\n; \\n[5] Victoria NEBOT, Rafael BERLANGA, \\nJuan Manuel PÉREZ, María José \\nARAMBURU, „ Multidimensional \\nIntegrated Ontologies: A Framework \\nFor Designing Semantic Data \\nWarehouses ”, http://goo.gl/ChCYdb\\n; \\n[6] Usama FAYYAD, Gregory \\nPIATETSKY-SHAPIRO, Padhraic \\nSMYTH, „From Data Mining to \\nKnowledge Discovery in Databases”, \\nhttp://goo.gl/EEJH4f\\n; 26  The Importance of Data Warehouses in the Developmen t… \\n  [7] Sandeepak BHANDARI, Tarun \\nSHARMA, Jagpreet SINGH, Sarabjit \\nKAUR, „ A Review: Data \\nWarehousing, Its Issues, Architecture \\nand Tools ”, International Journal for \\nInnovative Research in Science & \\nTechnology, Volume 1, Issue 3,  \\nAugust 2014, ISSN: 2349-6010; \\n[8] Joseph M. FIRESTONE, „DKMS \\nBrief No. Six: Data Warehouses, \\nData Marts, and Data Warehousing: \\nNew Definitions and New \\nConceptions” , http://goo.gl/VcSOkp\\n; [9] Ralph KIMBALL, Margy ROSS, „The \\nData Warehouse Toolkit: Second \\nEdition”, Wiley Computer Publishing, \\n2002, ISBN 0-471-20024-7; \\n[10] TDWI Data Warehousing \\nArchitectures: Choosing The Right Data \\nWarehousing Approach , 2005, \\nhttp://goo.gl/rpdmV6\\n; \\n[11] W. H. INMON, Claudia IMHOFF, \\nRyan SOUSA, ” Corporate Information \\nFactory, 2nd Edition ”, John Wiley & \\nSons, 2001, ISBN: 978-0-471-39961-2; \\n \\n \\n \\nAlexandru Adrian \\nȚ\\nOLE (born in 1986, Romania)\\n \\ngraduated from the \\nSchool of Domestic and International Business, Bank ing and Finance, the \\nRomanian – American University, in 2009. He also gr aduated the \\nScientific Master Program in Finance, Banking and I nsurance. He works \\nat the Ministry for Information Society. He is purs uing a PhD Program in \\nthe area of Executive Information Systems. \\n \\n \\n \\n \\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the text into smaller chunks to ensure the transformer won't hit tokens (words) size limits:\n",
        "the approach is to make sure each chunk is under token size limit and one by one they present the information within the whole text\n",
        " ps: the chunks are each phrase of the text"
      ],
      "metadata": {
        "id": "p19Uvdx_GZPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter= CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len\n",
        ")\n",
        "texts=text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "dSfr5HmQGYtw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "ffVgXmQPHJEh",
        "outputId": "e2f7d540-6773-419c-80f6-e7f66452541c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'18  The Importance of Data Warehouses in the Developmen t… \\n  The Importance of Data Warehouses  \\nin the Development of Computerized Decision Support  Solutions.  \\nA Comparison between Data Warehouses and Data Marts  \\n \\nAlexandru Adrian ȚOLE \\nRomanian – American University, Bucharest, Romania \\nalexandru.tole@gmail.com\\n \\n \\nIn the last decade, the amount of data that an orga nization processes and stores has grown'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings= OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "373pOeePHJ5h"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch= FAISS.from_texts(texts,embeddings)\n",
        "docsearch"
      ],
      "metadata": {
        "id": "YT9EmWWLLs5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "7pG03yrlNUNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain= load_qa_chain(OpenAI(),chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "gRo6qjLANpiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the final step you just enter the query/question and the model answers based on similarity with the docs text\n",
        "\n",
        "It will transform the query to embedding than calculate similarity with the embeddings of the docs based on that the model will generate response\n",
        "\n",
        "```\n",
        "# Ce texte est au format code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "xsNIYuHDNtKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question='What is a data warehouse'\n",
        "docs= docsearch.similarity_search(question)\n",
        "chain.run (input_documents=docs,question=question)"
      ],
      "metadata": {
        "id": "ip36vxM0NVOV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}